{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Data Science and Machine Learning Capstone Project</h1>\n",
    "<p style=\"text-align:center\">IBM: DS0720EN</p>\n",
    "<img style=\"text-align:center\" src=\"https://prod-edxapp.edx-cdn.org/static/edx.org/images/logo.790c9a5340cb.png\">\n",
    "<p style=\"text-align:center\">File Handling</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datasource\"></a>\n",
    "### Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>The course provides the data sources to use as these:\n",
    "    \n",
    "[New York City 311 SODA API Endpoint](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9)<br/>\n",
    "[Primary Land Use Tax Lot Output PLUTO housing dataset](https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_18v1.zip).\n",
    "\n",
    "<li>A little poking around yields two additional resources: \n",
    "    \n",
    "[Open Data Page schema](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9)<br/>\n",
    "[SODA documentation](https://dev.socrata.com/foundry/data.cityofnewyork.us/fhrw-4uyv)\n",
    "\n",
    "<li>The course provides a link that lets us download a subset of the entire 311 data set.  Only certain columns, sets a maximum number of rows, and limits to the Department of Housing Preservation and Development:\n",
    "    \n",
    "[SODA URL](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status)\n",
    "\n",
    "<li>I will create two additional SODA URL to use for this project:\n",
    "<li>Because the first quiz asks questions only pertaining through December 2018:\n",
    "\n",
    "[Through 2018 Only](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status&$where=created_date%3C%3D%272018-12-31T23:59:59.999%27)\n",
    "\n",
    "<li>The data set is still very large, so I will break off just one year to use during initial examination when I am figuring out what approach I will take:  \n",
    "\n",
    "[2018 Only](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status&$where=created_date%20between%20%272018-01-01T00:00:00.000%27%20and%20%272018-12-31T23:59:59.999%27)\n",
    "\n",
    "<li>The data sets will be read directly into a Pandas Dataframe then saved as \"pickle\" files.  Either locally or in the IBM Cloud, depending on where the notebook is being run.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status&$where=created_date%3C%3D%272018-12-31T23:59:59.999%27\", parse_dates=[1,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datacloud\"></a>\n",
    "### IBM Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippets for Uploading and Downloading pickle files between a Pandas data frame and the IBM Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import IBM specific imports here.\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables needed for IBM Cloud operations.\n",
    "\n",
    "# The values needed to replace the \"xxx\" placeholders in the following sections should be kept secret.\n",
    "# Do not keep them in any notebook that is then uploaded to anywhere publically visible.\n",
    "# These can be obtained by invoking the Watson Studio \"insert to code\" functionality on any uploaded file.\n",
    "# That will generate code with the required values.\n",
    "# Copy / paste from that generated code then discard the generated code.\n",
    "\n",
    "# Create a credentials variable.\n",
    "client_cred = ibm_boto3.client(service_name='xxx',\n",
    "ibm_api_key_id='xxx',\n",
    "ibm_auth_endpoint='xxx',\n",
    "config=Config(signature_version='xxx'),\n",
    "endpoint_url='xxx')\n",
    "\n",
    "# Create a bucket variable.\n",
    "bucket = 'xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Save\"\n",
    "#Create a pickle file from a dataframe:\n",
    "df.to_pickle('./ny311.pkl')\n",
    "#Upload a pickle (PKL) file to the IBM Cloud Object Store:\n",
    "client_cred.upload_file('./ny311.pkl',bucket,'ny311_cos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Load\"\n",
    "#Download a pickle file from IBM Cloud Object Store:\n",
    "client_cred.download_file(Bucket=bucket,Key='ny311_cos.pkl',Filename='./ny311.pkl')\n",
    "#Fill a Dataframe from of the pickle file:\n",
    "df = pd.read_pickle('./ny311.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datalocal\"></a>\n",
    "### Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid using up IBM Cloud monthly Capacity Unit Hours (CUH) while working on the notebook, the notebook can be hosted on a local machine runnning Jupyter Notebook.  Here are some code snippets for saving and loading Pandas data frames as local files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#set variables to make either operation easier\n",
    "file_path_local = 'C:\\\\Users\\\\It_Co\\\\Documents\\\\DataScience\\\\Capstone\\\\'\n",
    "filename_full = 'ny311full.pkl'\n",
    "filename_small = 'ny311small.pkl'\n",
    "filename_truncated = 'ny311truncated.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "#Create a pickle file from a dataframe.\n",
    "df.to_pickle(file_path_local + filename_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load\n",
    "#Fill a dataframe from a pickle file.\n",
    "df = pd.read_pickle(file_path_local + filename_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

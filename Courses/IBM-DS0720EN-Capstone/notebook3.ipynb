{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Data Science and Machine Learning Capstone Project</h1>\n",
    "<img style=\"float:right\" src=\"https://prod-edxapp.edx-cdn.org/static/edx.org/images/logo.790c9a5340cb.png\">\n",
    "<p style=\"text-align:center\">IBM: DS0720EN</p>\n",
    "<p style=\"text-align:center\">Question 3 of 4</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Problem Statement](#problem)\n",
    "2. [Question 3](#question)\n",
    "3. [Data Cleaning and Standardization](#wrangling)\n",
    "4. [Analyzing and Visualizing](#analysis)\n",
    "5. [Concluding Remarks](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problem\"></a>\n",
    "# Problem Statement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The people of New York use the 311 system to report complaints about the non-emergency problems to local authorities. Various agencies in New York are assigned these problems. The Department of Housing Preservation and Development of New York City is the agency that processes 311 complaints that are related to housing and buildings.\n",
    "\n",
    "In the last few years, the number of 311 complaints coming to the Department of Housing Preservation and Development has increased significantly. Although these complaints are not necessarily urgent, the large volume of complaints and the sudden increase is impacting the overall efficiency of operations of the agency.\n",
    "\n",
    "Therefore, the Department of Housing Preservation and Development has approached your organization to help them manage the large volume of 311 complaints they are receiving every year.\n",
    "\n",
    "The agency needs answers to several questions. The answers to those questions must be supported by data and analytics. These are their  questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"question\"></a>\n",
    "# Question 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the Complaint Type that you identified in response to Question 1 have an obvious relationship with any particular characteristic or characteristic of the Houses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "Determine how to link the NY311 data with the PLUTO data then identify whether or not there are any correlations between the HEAT/HOT WATER complaints from Question 1 to the PLUTO house information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Separately from this notebook:\n",
    "\n",
    "The [New York 311](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9) data was loaded by [SODA](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status) into a Pandas DataFrame then saved to a pickle file.\n",
    "\n",
    "The [New York PLUTO](https://data.cityofnewyork.us/City-Government/Primary-Land-Use-Tax-Lot-Output-PLUTO-/xuk2-nczf) data was downloaded.  The instructions at ( Course / 1. Project Challenge Details and Setup / Datasets Used in this Course / Datasets ) said \"Use only the part that is specific to the borough that you are interested in based on your analysis.\"  My answer for Question 2 suggested the borough with the biggest HEAT/HOT WATER problem was BRONX.  For that reason, only the BX_18v1.csv file was loaded into a Pandas DataFrame then saved to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5862383, 15)\n",
      "(89854, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "files_path = 'C:\\\\Users\\\\It_Co\\\\Documents\\\\DataScience\\\\Capstone\\\\' #local\n",
    "#files_path = './' #IBM Cloud / Watson Studio\n",
    "#pluto_columns = ['Address','BldgArea','BldgDepth','BuiltFAR','CommFAR','FacilFAR','Lot','LotArea','LotDepth','NumBldgs','NumFloors','OfficeArea','ResArea','ResidFAR','RetailArea','YearBuilt','YearAlter1','ZipCode','YCoord','XCoord']\n",
    "df = pd.read_pickle(files_path + 'ny311full.pkl')\n",
    "bx = pd.read_pickle(files_path + 'BX_18v1.pkl')\n",
    "print(df.shape)\n",
    "print(bx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"wrangling\"></a>\n",
    "# Data Cleaning and Standardization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NY 311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\It_Co\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\It_Co\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#Normalize relevant strings to uppercase so different casing won't appear as separate values.\n",
    "df['incident_address'] = df['incident_address'].str.upper()\n",
    "df['city'] = df['city'].str.upper()\n",
    "df['borough'] = df['borough'].str.upper()\n",
    "#We only care if it is the combined \"heating and hot water\" from Question 1, or some other type of complaint.\n",
    "df[df[\"complaint_type\"].isin([\"HEAT/HOT WATER\",\"HEATING\"])==True][\"complaint_type\"] = \"HEAT/HOT WATER\"\n",
    "df[df[\"complaint_type\"].isin([\"HEAT/HOT WATER\",\"HEATING\"])==False][\"complaint_type\"] = \"OTHER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Borough\n",
    "Leveraging findings found while standardizing during Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Correct rows where borough was entered in the city column with \"UNSPECIFIED\" in the borough column.\n",
    "five_boroughs = [\"BROOKLYN\",\"BRONX\",\"MANHATTAN\",\"QUEENS\",\"STATEN ISLAND\"]\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(five_boroughs)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=df.loc[which_rows_to_adjust,'city']\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan\n",
    "#Drop a few rows of ambiguous data.\n",
    "df.drop(df[(df[\"borough\"]=='MANHATTAN')&(df[\"city\"]=='BRONX')].index, axis=0, inplace=True)\n",
    "#Fill in UNSPECIFIED borough when city was entered as NEW YORK.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"MANHATTAN\"\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan\n",
    "#Although the city for most of the \"NEW YORK\" ones are the only ones that technically got the \"city\" column valued correctly,\n",
    "#since every other row uses city as \"neighborhood\":  Standardize these.\n",
    "which_rows_to_adjust = df[(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan\n",
    "#Any still unspecified boroughs are in Queens.\n",
    "queens_neighborhoods = df[(df['borough']=='UNSPECIFIED')&(df['city'].isnull()==False)]['city'].unique()\n",
    "#Standardize borough for Queens neighborhoods.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(queens_neighborhoods)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"QUEENS\"\n",
    "#Null the borough if it still shows up as unspecified borough as there is no other information from which to derive it.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isnull()].index\n",
    "df.loc[which_rows_to_adjust,'borough']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            658545\n",
       "BROOKLYN         636554\n",
       "MANHATTAN        457638\n",
       "QUEENS           266565\n",
       "STATEN ISLAND     20881\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX    658545\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[(df[\"borough\"]!='BRONX')].index, axis=0, inplace=True)\n",
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658545, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns deemed unnecessary for this question.\n",
    "df.drop(['created_date','complaint_type','street_name','address_type','city','resolution_description','borough','latitude','longitude','closed_date','location_type','status'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10467.0    62732\n",
       "10458.0    62230\n",
       "10468.0    55022\n",
       "10453.0    54877\n",
       "10452.0    47450\n",
       "10457.0    43311\n",
       "10456.0    42078\n",
       "10462.0    37637\n",
       "10472.0    32286\n",
       "10463.0    32069\n",
       "10460.0    31386\n",
       "10451.0    25170\n",
       "10466.0    22780\n",
       "10459.0    22192\n",
       "10455.0    16213\n",
       "10461.0    15465\n",
       "10454.0    10199\n",
       "10469.0     9899\n",
       "10473.0     8910\n",
       "10470.0     7454\n",
       "10474.0     5844\n",
       "10471.0     3759\n",
       "10465.0     2435\n",
       "10475.0      832\n",
       "10464.0      354\n",
       "10803.0        4\n",
       "Name: incident_zip, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['incident_zip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NY PLUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize relevant strings to uppercase so different casing won't appear as separate values.\n",
    "bx['Address'] = df['Address'].str.upper()\n",
    "bx['city'] = df['city'].str.upper()\n",
    "bx['borough'] = df['borough'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "# Analyzing and Visualizing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.complaint_type.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">None of the complaint types are null.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complaint_type'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">HEAT/HOT WATER is the most common of the 29 unique complaint types, but closer examination is necessary to make a final answer to the question.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = df['complaint_type'].unique()\n",
    "unique_types.sort()\n",
    "unique_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Some of these appear to be duplicate ways to represent the same thing.  The Open Data Page does not provide any clarification of these values, in case for example, water leaks should be lumped in with plumbing.  In a more real situation we could ask for such clarification.  If that was not available an analysis of whether apparent duplicates come from different Open_Data_Channel_Type could help formulate the best guess why there are apparent duplicates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Although we may need dummy values for later questions, for now just normalize the data in-place.\n",
    "#Using best guess interpretation about which complaint types are equivalent to each other.\n",
    "df['complaint_type'].replace('Appliance', 'APPLIANCE', inplace = True)\n",
    "df['complaint_type'].replace('GENERAL CONSTRUCTION', 'CONSTRUCTION', inplace = True)\n",
    "df['complaint_type'].replace('General', 'GENERAL', inplace = True)\n",
    "df['complaint_type'].replace('HEATING', 'HEAT/HOT WATER', inplace = True)\n",
    "df['complaint_type'].replace('Outside Building', 'OUTSIDE BUILDING', inplace = True)\n",
    "df['complaint_type'].replace('PAINT - PLASTER', 'PAINT/PLASTER', inplace = True)\n",
    "df['complaint_type'].replace('Plumbing', 'PLUMBING', inplace = True)\n",
    "df['complaint_type'].replace('Safety', 'SAFETY', inplace = True)\n",
    "df['complaint_type'].replace('Unsanitary Condition', 'UNSANITARY CONDITION', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['complaint_type'].describe())\n",
    "unique_types = df['complaint_type'].unique()\n",
    "unique_types.sort()\n",
    "unique_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Twenty complaint types after consolidating obvious duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (1 - 2040461.00 / 5862383.00) # taking values from the \"describe\" statement above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">HEAT/HOT WATER represents almost 2/3 of the complaints.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"complaint_type\"].value_counts())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The next two or three most common complaints combined happen less.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Let's take a more visual look, just to double check.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a bar chart to show how many of each type of complaint.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "totals = pd.DataFrame(df['complaint_type'].value_counts())\n",
    "totals.plot(kind='bar', figsize=(10,6), rot=90)\n",
    "plt.xlabel(\"Complaint Type\")\n",
    "plt.ylabel(\"Number of Complaints\")\n",
    "plt.title(\"Number of complaints by type\")\n",
    "plt.annotate('', xycoords='data', xy=(1, 2000000), xytext=(5, 1500000), arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='r', lw=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Clearly, nothing else comes close to HEAT/HOT WATER over the entire data set.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Perhaps the top complaint changes over time and HEAT/HOT WATER is only the top one in aggregate?  Let's see if that has been the case by also looking at totals for each individual year.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Year column.\n",
    "def strleft(s):\n",
    "    return s[0:4]\n",
    "df['Year'] = df['created_date'].apply(strleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine unique list of years.\n",
    "unique_years = df['Year'].unique()\n",
    "unique_years.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate yearly totals\n",
    "import numpy as np\n",
    "yearly_totals = pd.DataFrame(index=unique_types, columns=unique_years)\n",
    "for y in unique_years:\n",
    "    values_this_year = df[df['Year']==y]['complaint_type'].value_counts()\n",
    "    for i in values_this_year.index:\n",
    "        yearly_totals.at[i,y] = values_this_year[i]\n",
    "yearly_totals.replace(np.nan, 0, inplace = True)\n",
    "yearly_totals = yearly_totals.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the number of complaints by type and year.\n",
    "yearly_totals.plot(kind=\"line\")\n",
    "plt.title('Complaints Over the Years')\n",
    "plt.ylabel('Number of Complaints')\n",
    "plt.xlabel('Year')\n",
    "plt.legend(bbox_to_anchor=(1.05,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The top complaint type consistently every year is HEAT/HOT WATER.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">All the totals drop off at the end.  This is because the data set is updated every day, but the final year 2019 is still in progress with almost three months to go.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "# Concluding Remarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HEAT/HOT WATER (including HEATING) complaint type identified in Question 1 as the most prevalent complaint type has (or does not have any????) an obvious relationship with the XXX house characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Data Science and Machine Learning Capstone Project</h1>\n",
    "<img style=\"float:right\" src=\"https://prod-edxapp.edx-cdn.org/static/edx.org/images/logo.790c9a5340cb.png\">\n",
    "<p style=\"text-align:center\">IBM: DS0720EN</p>\n",
    "<p style=\"text-align:center\">Question 2 of 4</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Problem Statement](#problem)\n",
    "2. [Question 2](#question)\n",
    "3. [Analyzing and Visualizing](#analysis)\n",
    "4. [Concluding Remarks](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problem\"></a>\n",
    "## Problem Statement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The people of New York use the 311 system to report complaints about the non-emergency problems to local authorities. Various agencies in New York are assigned these problems. The Department of Housing Preservation and Development of New York City is the agency that processes 311 complaints that are related to housing and buildings.\n",
    "\n",
    "In the last few years, the number of 311 complaints coming to the Department of Housing Preservation and Development has increased significantly. Although these complaints are not necessarily urgent, the large volume of complaints and the sudden increase is impacting the overall efficiency of operations of the agency.\n",
    "\n",
    "Therefore, the Department of Housing Preservation and Development has approached your organization to help them manage the large volume of 311 complaints they are receiving every year.\n",
    "\n",
    "The agency needs answers to several questions. The answers to those questions must be supported by data and analytics. These are their  questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"question\"></a>\n",
    "## Question 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the Department of Housing Preservation and Development of New York City focus on any particular set of boroughs, ZIP codes, or street (where the complaints are severe) for the specific type of complaints you identified in response to Question 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "Analyze the data to see if there is a higher correlation between the HEATING complaints and any particular borough, ZIP code, or street."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Separately the [New York 311](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9) data was loaded by [SODA](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status) into a Pandas DataFrame then saved to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5862383, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('C:\\\\Users\\\\It_Co\\\\Documents\\\\DataScience\\\\Capstone\\\\ny311full.pkl') # Local\n",
    "#df = pd.read_pickle('./ny311.pkl') #IBM Cloud / Watson Studio\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "## Analyzing and Visualizing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce data to relevant rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEAT/HOT WATER    1152592\n",
       "HEATING            887869\n",
       "Name: complaint_type, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove rows that were not for the complaint types identified in question one.\n",
    "df.drop(df[df[\"complaint_type\"].isin([\"HEAT/HOT WATER\",\"HEATING\"])==False].index, inplace=True)\n",
    "#Double check that the correct rows were removed.\n",
    "df['complaint_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2040461, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns deemed unnecessary for this question.\n",
    "df.drop(['created_date','complaint_type','resolution_description','closed_date','location_type','status','address_type'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle any unruly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize strings so different casing won't appear as separate values.\n",
    "df['incident_address'] = df['incident_address'].str.upper()\n",
    "df['street_name'] = df['street_name'].str.upper()\n",
    "df['city'] = df['city'].str.upper()\n",
    "df['borough'] = df['borough'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key              0\n",
       "incident_zip        18970\n",
       "incident_address        1\n",
       "street_name             1\n",
       "city                18843\n",
       "borough                 0\n",
       "latitude            18966\n",
       "longitude           18966\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if any data is null.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">How is it that the city could ever be missing, when the borough is not?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            569960\n",
       "BROOKLYN         543166\n",
       "MANHATTAN        398552\n",
       "UNSPECIFIED      282917\n",
       "QUEENS           228447\n",
       "STATEN ISLAND     17419\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The expected five boroughs, but then also:  UNSPECIFIED.  What does that mean?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BROOKLYN               93388\n",
       "BRONX                  88585\n",
       "NEW YORK               59095\n",
       "JAMAICA                 5020\n",
       "STATEN ISLAND           3462\n",
       "ASTORIA                 3381\n",
       "FLUSHING                3154\n",
       "RIDGEWOOD               2273\n",
       "FAR ROCKAWAY            2040\n",
       "WOODSIDE                1773\n",
       "ELMHURST                1696\n",
       "JACKSON HEIGHTS         1479\n",
       "CORONA                  1398\n",
       "FOREST HILLS            1340\n",
       "REGO PARK               1134\n",
       "SOUTH RICHMOND HILL     1005\n",
       "QUEENS VILLAGE           928\n",
       "SUNNYSIDE                877\n",
       "OZONE PARK               835\n",
       "RICHMOND HILL            778\n",
       "HOLLIS                   776\n",
       "WOODHAVEN                770\n",
       "EAST ELMHURST            752\n",
       "SPRINGFIELD GARDENS      675\n",
       "SAINT ALBANS             660\n",
       "SOUTH OZONE PARK         606\n",
       "KEW GARDENS              599\n",
       "ARVERNE                  589\n",
       "LONG ISLAND CITY         454\n",
       "ROSEDALE                 416\n",
       "OAKLAND GARDENS          397\n",
       "MASPETH                  363\n",
       "ROCKAWAY PARK            361\n",
       "BAYSIDE                  236\n",
       "COLLEGE POINT            225\n",
       "FRESH MEADOWS            225\n",
       "MIDDLE VILLAGE           221\n",
       "LITTLE NECK              159\n",
       "WHITESTONE               139\n",
       "HOWARD BEACH             127\n",
       "CAMBRIA HEIGHTS          127\n",
       "GLEN OAKS                 56\n",
       "BELLEROSE                 45\n",
       "FLORAL PARK               18\n",
       "BREEZY POINT               6\n",
       "QUEENS                     3\n",
       "NEW HYDE PARK              2\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"borough\"]==\"UNSPECIFIED\"][\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  When the borough is UNSPECIFIED it appears to mean that often either the borough <i>or even a \"neighborhood\" (a division below borough)</i> has been entered in the CITY column.  The city is actually \"correct\" with NEW YORK only 59K times.  The city column is a de-facto \"neighborhood\" column for the most part.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Because borough is something further analysis will key from, fix the data where possible.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Correct rows where borough was entered in the city column with \"UNSPECIFIED\" in the borough column.\n",
    "five_boroughs = [\"BROOKLYN\",\"BRONX\",\"MANHATTAN\",\"QUEENS\",\"STATEN ISLAND\"]\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(five_boroughs)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=df.loc[which_rows_to_adjust,'city']\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Almost 200K previously \"UNSPECIFIED\" rows will now show up under the correct borough during later analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MANHATTAN      393941\n",
       "UNSPECIFIED     59095\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if all the boroughs encompassed when the CITY is showing up as \"New York\"\n",
    "df[df['city']=='NEW YORK']['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEW YORK    393941\n",
       "BRONX            9\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if all the MANHATTAN borough entries filled in the CITY as \"New York\" if if they sometimes have \"neighborhood\".\n",
    "df[df['borough']=='MANHATTAN']['city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  Some data entered very oddly with BRONX as the city and MANHATTAN as the borough.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Ambiguous and only 9 rows out of millions, so drop the data so it won't confuse further analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040461, 8)\n",
      "(2040452, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #before\n",
    "#Drop a few rows of ambiguous data.\n",
    "df.drop(df[(df[\"borough\"]=='MANHATTAN')&(df[\"city\"]=='BRONX')].index, axis=0, inplace=True)\n",
    "print(df.shape) #after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There are almost 400K rows with city as NEW YORK and the borough is MANHATTAN.  The other 59K rows with city NEW YORK has UNSPECIFIED as the borough.  Assume the borough is also MANHATTAN for those.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in UNSPECIFIED borough when city was entered as NEW YORK.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"MANHATTAN\"\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Although the city for most of the \"NEW YORK\" ones are the only ones that technically got the \"city\" column valued correctly,\n",
    "#since every other row uses city as \"neighborhood\":  Make these consistent.\n",
    "which_rows_to_adjust = df[(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            658545\n",
       "BROOKLYN         636554\n",
       "MANHATTAN        457638\n",
       "QUEENS           228450\n",
       "UNSPECIFIED       38384\n",
       "STATEN ISLAND     20881\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check how many unspecified boroghs\n",
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There are still 38K rows with unspecified boroughs, but the neighborhoods are in the city column, so use them to map to boroughs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARVERNE', 'ASTORIA', 'BAYSIDE', 'BELLEROSE', 'BREEZY POINT',\n",
       "       'CAMBRIA HEIGHTS', 'COLLEGE POINT', 'CORONA', 'EAST ELMHURST',\n",
       "       'ELMHURST', 'FAR ROCKAWAY', 'FLORAL PARK', 'FLUSHING',\n",
       "       'FOREST HILLS', 'FRESH MEADOWS', 'GLEN OAKS', 'HOLLIS',\n",
       "       'HOWARD BEACH', 'JACKSON HEIGHTS', 'JAMAICA', 'KEW GARDENS',\n",
       "       'LITTLE NECK', 'LONG ISLAND CITY', 'MASPETH', 'MIDDLE VILLAGE',\n",
       "       'NEW HYDE PARK', 'OAKLAND GARDENS', 'OZONE PARK', 'QUEENS VILLAGE',\n",
       "       'REGO PARK', 'RICHMOND HILL', 'RIDGEWOOD', 'ROCKAWAY PARK',\n",
       "       'ROSEDALE', 'SAINT ALBANS', 'SOUTH OZONE PARK',\n",
       "       'SOUTH RICHMOND HILL', 'SPRINGFIELD GARDENS', 'SUNNYSIDE',\n",
       "       'WHITESTONE', 'WOODHAVEN', 'WOODSIDE'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the neighborhoods of the still unspecified boroughs.\n",
    "neighborhoods = df[(df['borough']=='UNSPECIFIED')&(df['city'].isnull()==False)]['city'].unique()\n",
    "neighborhoods.sort()\n",
    "neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  Checking https://en.wikipedia.org/wiki/List_of_Queens_neighborhoods show all but NEW HYDE PARK are in QUEENS.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  NEW HYDE PARK isn't in any borough but is right on the border with QUEENS, and had only 2 complaints, so just consider it within QUEEENS.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            658545\n",
       "BROOKLYN         636554\n",
       "MANHATTAN        457638\n",
       "QUEENS           266565\n",
       "STATEN ISLAND     20881\n",
       "UNSPECIFIED         269\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fix rows with unspecified borough but with a neighborhood (in the city column) that indicates it is in QUEEENS.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(neighborhoods)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"QUEENS\"\n",
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">This will ultimately become the raw numbers to partially answer part of the the question.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incident_zip  latitude  longitude\n",
       "count           0.0       0.0        0.0\n",
       "mean            NaN       NaN        NaN\n",
       "std             NaN       NaN        NaN\n",
       "min             NaN       NaN        NaN\n",
       "25%             NaN       NaN        NaN\n",
       "50%             NaN       NaN        NaN\n",
       "75%             NaN       NaN        NaN\n",
       "max             NaN       NaN        NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine rows for those final 269 unspecified boroughs\n",
    "df[df['borough']=='UNSPECIFIED'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Nothing \"worth the trouble\" to base further adjustments on for only 269 rows.  Set the borough to null on these rows so that they will not skew any subsequent analysis that examines borough.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with unspecified borough and no other practical information from which to derive it.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isnull()].index\n",
    "df.loc[which_rows_to_adjust,'borough']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with city (neighborhood) equal to borough\n",
    "which_rows_to_adjust = df[(df[\"borough\"]==df[\"city\"])].index\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with city that started off null or was adjusted subsequently to be null\n",
    "which_rows_to_adjust = df[df[\"city\"].isnull()].index\n",
    "df.loc[which_rows_to_adjust,'city']=\"Unspecified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">At this point borough is reasonably populated with all the UNSPECIFIED and weird cases mitigated.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The question calls for using zip code too.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>borough</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18969</td>\n",
       "      <td>18969</td>\n",
       "      <td>18970</td>\n",
       "      <td>18701</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8306</td>\n",
       "      <td>2205</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>40931525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34 ARDEN STREET</td>\n",
       "      <td>GRAND CONCOURSE</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>365</td>\n",
       "      <td>18970</td>\n",
       "      <td>5957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key  incident_zip incident_address      street_name  \\\n",
       "count       18970           0.0            18969            18969   \n",
       "unique      18970           NaN             8306             2205   \n",
       "top      40931525           NaN  34 ARDEN STREET  GRAND CONCOURSE   \n",
       "freq            1           NaN              232              365   \n",
       "mean          NaN           NaN              NaN              NaN   \n",
       "std           NaN           NaN              NaN              NaN   \n",
       "min           NaN           NaN              NaN              NaN   \n",
       "25%           NaN           NaN              NaN              NaN   \n",
       "50%           NaN           NaN              NaN              NaN   \n",
       "75%           NaN           NaN              NaN              NaN   \n",
       "max           NaN           NaN              NaN              NaN   \n",
       "\n",
       "               city borough   latitude  longitude  \n",
       "count         18970   18701   4.000000   4.000000  \n",
       "unique            1       5        NaN        NaN  \n",
       "top     Unspecified   BRONX        NaN        NaN  \n",
       "freq          18970    5957        NaN        NaN  \n",
       "mean            NaN     NaN  40.724393 -73.849776  \n",
       "std             NaN     NaN   0.000000   0.000000  \n",
       "min             NaN     NaN  40.724393 -73.849776  \n",
       "25%             NaN     NaN  40.724393 -73.849776  \n",
       "50%             NaN     NaN  40.724393 -73.849776  \n",
       "75%             NaN     NaN  40.724393 -73.849776  \n",
       "max             NaN     NaN  40.724393 -73.849776  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There were some null zip codes seen before.  Examine them more closely.\n",
    "df[df['incident_zip'].isnull()==True].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Nothing \"worth the trouble\" to base further adjustments for the missing zip codes.  If these 18K rows were deemed super important, a library for looking up a zip code based on an address would be necessary.  Just leave them as NaN values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18970, 8)\n",
      "(2021482, 8)\n",
      "(2021482, 8)\n",
      "(0, 8)\n",
      "(0, 8)\n",
      "(2021482, 8)\n"
     ]
    }
   ],
   "source": [
    "#Learn the nature of the zip code data.\n",
    "print(df[(df['incident_zip'].isnull()==True)].shape)\n",
    "print(df[(df['incident_zip'].isnull()==False)].shape)\n",
    "print(df[(df['incident_zip'].isnull()==False)&(df['incident_zip'] % 1.0 == 0.0)].shape)\n",
    "print(df[(df['incident_zip']<10000.0)].shape)\n",
    "print(df[(df['incident_zip']>99999.0)].shape)\n",
    "print(df[(df['incident_zip']>9999.0)&(df['incident_zip']<100000.0)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  The zip codes are all float64.  All of them have zero after the decimal point.  They are all five digits before the decimal point.  Almost 19K of the 2 Million+ rows are null.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The question calls for using street too.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>borough</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251660</th>\n",
       "      <td>21833329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key  incident_zip incident_address street_name         city  \\\n",
       "251660   21833329           NaN              NaN         NaN  Unspecified   \n",
       "\n",
       "       borough  latitude  longitude  \n",
       "251660   BRONX       NaN        NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There was only one row with a null street.  Can it be repaired from address or anything?\n",
    "df[df['street_name'].isnull()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Get rid of it.  Just one row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040452, 8)\n",
      "(2040451, 8)\n"
     ]
    }
   ],
   "source": [
    "#Remove row with null street.\n",
    "print(df.shape)\n",
    "df.drop(df[df[\"street_name\"].isnull()==True].index, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRAND CONCOURSE             35960\n",
       "BROADWAY                    23497\n",
       "OCEAN AVENUE                17882\n",
       "ARDEN STREET                15841\n",
       "MORRIS AVENUE               15792\n",
       "ST NICHOLAS AVENUE          14945\n",
       "AMSTERDAM AVENUE            11844\n",
       "ELMHURST AVENUE             10946\n",
       "BOYNTON AVENUE              10809\n",
       "DR M L KING JR BOULEVARD    10037\n",
       "OCEAN PARKWAY                9965\n",
       "WALTON AVENUE                9579\n",
       "BAILEY AVENUE                9561\n",
       "RIVERSIDE DRIVE              9189\n",
       "LINDEN BOULEVARD             9173\n",
       "SEDGWICK AVENUE              9111\n",
       "DECATUR AVENUE               9095\n",
       "NOSTRAND AVENUE              8826\n",
       "CRESTON AVENUE               8683\n",
       "SHERMAN AVENUE               7885\n",
       "BEDFORD AVENUE               7530\n",
       "SHERIDAN AVENUE              7502\n",
       "EASTERN PARKWAY              7424\n",
       "3 AVENUE                     7323\n",
       "WALLACE AVENUE               7287\n",
       "2 AVENUE                     7172\n",
       "DAVIDSON AVENUE              6840\n",
       "FT WASHINGTON AVENUE         6698\n",
       "NEW YORK AVENUE              6663\n",
       "VALENTINE AVENUE             6565\n",
       "                            ...  \n",
       "E MOSHOLU PARKWAY N             1\n",
       "FREDRICK DOUGLAS BLVD           1\n",
       "BRIGHTON 2 PLACE                1\n",
       "HOLBERNT COURT                  1\n",
       "BRIGHTON 3 PLACE                1\n",
       "OCEAN TERRACE                   1\n",
       "93 ROAD                         1\n",
       "FLATLANDS    4 STREET           1\n",
       "CRESTON AVE                     1\n",
       "ASPINWALL STREET                1\n",
       "MITCHELL LANE                   1\n",
       "235 COURT                       1\n",
       "SUFFOLK DRIVE                   1\n",
       "ELMHURST AVE                    1\n",
       "SATURN LANE                     1\n",
       "PROVOST AVENUE                  1\n",
       "BARTOW STREET                   1\n",
       "HAIGHT STREET                   1\n",
       "LANDER AVENUE                   1\n",
       "NEW DORP LANE                   1\n",
       "COLUMBIA STREETDUMMY            1\n",
       "E 12 ST                         1\n",
       "CYRUS AVENUE                    1\n",
       "ASTORIA PARK SOUTH              1\n",
       "VANBUREN STREET                 1\n",
       "269 STREET                      1\n",
       "WEST 145 ST                     1\n",
       "WATERSTONE DRIVE                1\n",
       "55 ST                           1\n",
       "DRAPER PLACE                    1\n",
       "Name: street_name, Length: 5979, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  Before any attempt at normalization, there are 5979 distinct street_name values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go home and re-think your life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "popular_suffixes = [\n",
    "    \"AVENUE\",\"STREET\",\"BOULEVARD\",\"PLACE\",\"ROAD\",\"PARKWAY\",\"CONCOURSE\",\"DRIVE\",\n",
    "    \"TERRACE\",\"HIGHWAY\",\"PARK\",\"EXPRESSWAY\",\"SQUARE\",\"PLAZA\",\"OVAL\",\"CRESCENT\",\n",
    "    \"LANE\",\"COURT\",\"EXTENSION\",\"TURNPIKE\", \"LOOP\",\"ESTATE\"]\n",
    "directionals = [\"SOUTH\",\"NORTH\",\"EAST\",\"WEST\"]\n",
    "popular_streets = [\"BROADWAY\",\"BOWERY\"]\n",
    "\n",
    "def street_mlk(street):\n",
    "    effective_street = street\n",
    "    effective_street = effective_street.replace(\"DR M L KING JR\",\"mlk\")\n",
    "    effective_street = effective_street.replace(\"DR MARTIN L KING\",\"mlk\")\n",
    "    effective_street = effective_street.replace(\"MARTIN LUTHER KING\",\"mlk\")\n",
    "    effective_street = effective_street.replace(\"MARTIN L KING JR\",\"mlk\")\n",
    "    effective_street = effective_street.replace(\"MARTIN L KING\",\"mlk\")\n",
    "    effective_street = effective_street.replace(\"mlk\",\"MARTIN LUTHER KING\")\n",
    "    return effective_street\n",
    "\n",
    "def fix_last_word(street, old, new):\n",
    "    split_street = street.split()\n",
    "    last_index = len(split_street) - 1\n",
    "    if split_street[last_index]==old:\n",
    "        split_street[last_index] = new\n",
    "    effective_street = \" \".join(split_street)\n",
    "    return effective_street\n",
    "\n",
    "def fix_middle_words(street, old, new):\n",
    "    split_street = street.split()\n",
    "    found_at_index = next((i for i, x in enumerate(split_street) if x==old), None)\n",
    "    last_index = len(split_street) - 1\n",
    "    if found_at_index!=None:\n",
    "        if found_at_index!=last_index:\n",
    "            split_street[found_at_index] = new\n",
    "    effective_street = \" \".join(split_street)\n",
    "    return effective_street\n",
    "\n",
    "def normalize_street(street):\n",
    "    effective_street = street.strip() #Remove leading and trailing spaces.\n",
    "    effective_street = re.sub(' +', ' ', effective_street) #Squeeze multiple spaces to one space.\n",
    "    \n",
    "    effective_street = street_mlk(effective_street)\n",
    "    effective_street = fix_last_word(effective_street,\"AVE\",\"AVENUE\")\n",
    "    effective_street = fix_last_word(effective_street,\"ST\",\"STREET\")\n",
    "    effective_street = fix_last_word(effective_street,\"RD\",\"ROAD\")\n",
    "    \n",
    "    split_street = effective_street.split()\n",
    "    last_word = split_street[-1]\n",
    "   \n",
    "    if street in popular_streets:\n",
    "        return \"accounted for - popular\"\n",
    "    if (len(split_street)==2)&(last_word in popular_suffixes):\n",
    "        return \"accounted for - 2 word normal\"\n",
    "    if (len(split_street)==2)&(split_street[0]==\"AVENUE\"):\n",
    "        return \"accounted for - avenue X\"\n",
    "    if (last_word in directionals)&(len(split_street)>2):\n",
    "        if (split_street[-2] in popular_suffixes):\n",
    "            return \"accounted for - normal with directional\"\n",
    "    if (len(split_street)==2)&(split_street[0] in directionals):\n",
    "        if (split_street[1] in popular_streets):\n",
    "            return \"accounted for - directional popular\"\n",
    "    \n",
    "    return effective_street\n",
    "    #return last_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_street_name'] = df['street_name'].apply(normalize_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accounted for - 2 word normal              1403563\n",
       "accounted for - normal with directional      28589\n",
       "accounted for - popular                      23619\n",
       "accounted for - avenue X                     18742\n",
       "ST NICHOLAS AVENUE                           14945\n",
       "MARTIN LUTHER KING BOULEVARD                 10244\n",
       "FT WASHINGTON AVENUE                          6698\n",
       "NEW YORK AVENUE                               6663\n",
       "ADAM C POWELL BOULEVARD                       6427\n",
       "EAST 21 STREET                                6013\n",
       "ST JOHNS PLACE                                5861\n",
       "EAST TREMONT AVENUE                           5809\n",
       "EAST 19 STREET                                5659\n",
       "ST MARKS AVENUE                               5292\n",
       "WHITE PLAINS ROAD                             4907\n",
       "FREDERICK DOUGLASS BOULEVARD                  4708\n",
       "EAST 18 STREET                                4509\n",
       "EAST 12 STREET                                3879\n",
       "WEST 141 STREET                               3753\n",
       "DE KALB AVENUE                                3689\n",
       "EAST 17 STREET                                3503\n",
       "WEST END AVENUE                               3484\n",
       "EAST 163 STREET                               3271\n",
       "WEST 135 STREET                               3213\n",
       "BEDFORD PARK BOULEVARD                        3164\n",
       "WEST 139 STREET                               3114\n",
       "EAST 169 STREET                               2949\n",
       "WEST 170 STREET                               2948\n",
       "EAST 14 STREET                                2736\n",
       "WEST 147 STREET                               2693\n",
       "                                            ...   \n",
       "BRIGHTON 8 PLACE                                 1\n",
       "ST JOSEPHS AVENUE                                1\n",
       "FREDRICK DOUGLAS BLVD                            1\n",
       "BELLA VISTA COURT                                1\n",
       "WARDS MEADOW LOOP                                1\n",
       "MATHER GASTON BOULEVARD                          1\n",
       "WEST VALLEY STREAM BOULEVARD                     1\n",
       "E 139 STREET                                     1\n",
       "BERGEN COVE                                      1\n",
       "FORT HAMILTON PARKWAY                            1\n",
       "SHORE ROAD LANE                                  1\n",
       "VAN HOESEN AVENUE                                1\n",
       "BRIGHTON 2 LANE                                  1\n",
       "W 141 STREET                                     1\n",
       "B 25 STREET                                      1\n",
       "ROCKAWAY BEACH BOULEVARDUMMY                     1\n",
       "BRIGHTON 3 COURT                                 1\n",
       "MC LAUGHLIN STREET                               1\n",
       "W 27 STREET                                      1\n",
       "MC DONOUGH PLACE                                 1\n",
       "EAST 278 STREET                                  1\n",
       "COLUMBIA STREETDUMMY                             1\n",
       "NEW DORP LANE                                    1\n",
       "HONG KONG STREET                                 1\n",
       "WINDING WOODS LOOP                               1\n",
       "HUTCH RIVER PARKWAY SR                           1\n",
       "W 147 STREET                                     1\n",
       "18                                               1\n",
       "BRIGHTON 5 PLACE                                 1\n",
       "E TREMONT STREET                                 1\n",
       "Name: normalized_street_name, Length: 1231, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalized_street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAST MOSHOLU PARKWAY SOUTH         2136\n",
       "ANDREWS AVENUE SOUTH               1722\n",
       "WEST MOSHOLU PARKWAY SOUTH         1558\n",
       "BRONX PARK SOUTH                   1475\n",
       "PELHAM PARKWAY SOUTH               1334\n",
       "LORING PLACE SOUTH                  433\n",
       "PARK LANE SOUTH                     280\n",
       "SHORE PARKWAY SR SOUTH              256\n",
       "PARK AVENUE SOUTH                   181\n",
       "HOYT AVENUE SOUTH                    98\n",
       "CENTRAL PARK SOUTH                   80\n",
       "HOR HARDING EXPRESSWAY SR SOUTH      60\n",
       "VAN CORTLANDT PARK SOUTH             56\n",
       "CROTONA PARK SOUTH                   48\n",
       "ASTORIA BOULEVARD SOUTH              31\n",
       "DELANCEY ST SOUTH                    30\n",
       "CROSS BRONX SERVICE ROAD SOUTH       25\n",
       "7 AVENUE SOUTH                       24\n",
       "NARROWS ROAD SOUTH                   12\n",
       "GRAND CENTRAL PARKWAY SR SOUTH       11\n",
       "VILLAGE ROAD SOUTH                    8\n",
       "GRAND CENTRAL PARKWAY SOUTH           7\n",
       "SUTTON PLACE SOUTH                    6\n",
       "JUNIPER BLVD SOUTH                    4\n",
       "229 DRIVE SOUTH                       3\n",
       "GRAMERCY PARK SOUTH                   3\n",
       "CROSS ISLAND PARKWAY SR SOUTH         3\n",
       "BELLAMY LOOP SOUTH                    3\n",
       "BRONX SOUTH                           2\n",
       "UNION SQUARE SOUTH                    1\n",
       "QN MIDTOWN EXPRESSWAY SR SOUTH        1\n",
       "QUEENS PLAZA SOUTH                    1\n",
       "CROSS BX SERVICE ROAD SOUTH           1\n",
       "ASTORIA PARK SOUTH                    1\n",
       "Name: street_name, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['normalized_street_name']=='SOUTH']['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['street_name'].isnull()==False)&(df['street_name'].str.contains('  '))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  The street names are not entirely normalized.  Some have multiple spaces in them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['street_name'].str.contains('CONCOURSE')]['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get  all words in the street_name column in a countable form.\n",
    "words = list()\n",
    "df['street_name'].str.split().apply(words.extend)\n",
    "word_series = pd.Series(words)\n",
    "counts = word_series.value_counts()\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.drop(counts[counts < 100].index, inplace=True) # Drop rare ones\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.drop(counts[counts.index.str.isdigit()].index, inplace=True) # Drop ones that are ONLY numbers\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['AVENUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVENUE\n",
    "#STREET\n",
    "#BOULEVARD\n",
    "#PLACE\n",
    "#ROAD\n",
    "#PARKWAY\n",
    "#CONCOURSE\n",
    "#PARK\n",
    "#TERRACE\n",
    "\n",
    "\n",
    "#EAST\n",
    "#WEST\n",
    "#SOUTH\n",
    "#NORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Finds</b>:  .</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_width_max = df['borough'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather totals for graphic\n",
    "totals_for_graph = df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "totals_for_graph.plot(kind='barh', figsize=(13, 4), color='steelblue')\n",
    "plt.xlim = (0, graph_width_max)\n",
    "plt.xlabel('Number of complaints')\n",
    "plt.title('HEATING / HOT WATER complaints by borough')\n",
    "for index, value in enumerate(totals_for_graph): \n",
    "    label = format(int(value), ',') # format int with commas\n",
    "    # place text at the end of bar (subtracting 47000 from x, and 0.1 from y to make it fit within the bar)\n",
    "    plt.annotate(label, xy=(value - 47000, index - 0.10), color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Concluding Remarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Department of Housing Preservation and Development of New York City should focus on the following particular set of boroughs, ZIP codes, and streets (where the complaints are severe) for the \"HEAT/HOT WATER\" + \"HEATING\" complaint types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">xxx</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

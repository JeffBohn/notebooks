{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Data Science and Machine Learning Capstone Project</h1>\n",
    "<img style=\"float:right\" src=\"https://prod-edxapp.edx-cdn.org/static/edx.org/images/logo.790c9a5340cb.png\">\n",
    "<p style=\"text-align:center\">IBM: DS0720EN</p>\n",
    "<p style=\"text-align:center\">Question 2 of 4</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Problem Statement](#problem)\n",
    "2. [Question 2](#question)\n",
    "3. [Analyzing and Visualizing](#analysis)\n",
    "4. [Concluding Remarks](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problem\"></a>\n",
    "## Problem Statement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The people of New York use the 311 system to report complaints about the non-emergency problems to local authorities. Various agencies in New York are assigned these problems. The Department of Housing Preservation and Development of New York City is the agency that processes 311 complaints that are related to housing and buildings.\n",
    "\n",
    "In the last few years, the number of 311 complaints coming to the Department of Housing Preservation and Development has increased significantly. Although these complaints are not necessarily urgent, the large volume of complaints and the sudden increase is impacting the overall efficiency of operations of the agency.\n",
    "\n",
    "Therefore, the Department of Housing Preservation and Development has approached your organization to help them manage the large volume of 311 complaints they are receiving every year.\n",
    "\n",
    "The agency needs answers to several questions. The answers to those questions must be supported by data and analytics. These are their  questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"question\"></a>\n",
    "## Question 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the Department of Housing Preservation and Development of New York City focus on any particular set of boroughs, ZIP codes, or street (where the complaints are severe) for the specific type of complaints you identified in response to Question 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "Analyze the data to see if there is a higher correlation between the HEATING complaints and any particular borough, ZIP code, or street."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Separately the [New York 311](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9) data was loaded by [SODA](https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?$limit=100000000&Agency=HPD&$select=created_date,unique_key,complaint_type,incident_zip,incident_address,street_name,address_type,city,resolution_description,borough,latitude,longitude,closed_date,location_type,status) into a Pandas DataFrame then saved to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5862383, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('C:\\\\Users\\\\It_Co\\\\Documents\\\\DataScience\\\\Capstone\\\\ny311full.pkl') # Local\n",
    "#df = pd.read_pickle('./ny311.pkl') #IBM Cloud / Watson Studio\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "### Analyzing and Visualizing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce data to relevant rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HEAT/HOT WATER    1152592\n",
       "HEATING            887869\n",
       "Name: complaint_type, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove rows that were not for the complaint types identified in question one.\n",
    "df.drop(df[df[\"complaint_type\"].isin([\"HEAT/HOT WATER\",\"HEATING\"])==False].index, inplace=True)\n",
    "#Double check that the correct rows were removed.\n",
    "df['complaint_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2040461, 8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns deemed unnecessary for this question.\n",
    "df.drop(['created_date','complaint_type','resolution_description','closed_date','location_type','status','address_type'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrangle (Clean) the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identify and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key              0\n",
       "incident_zip        18970\n",
       "incident_address        1\n",
       "street_name             1\n",
       "city                18843\n",
       "borough                 0\n",
       "latitude            18966\n",
       "longitude           18966\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if any data is null.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Analysis</b>:  There are three items the question hinges upon:  ZIP Code, Borough, and Street.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>borough</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18969</td>\n",
       "      <td>18969</td>\n",
       "      <td>127</td>\n",
       "      <td>18970</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8306</td>\n",
       "      <td>2205</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>24973466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34 ARDEN STREET</td>\n",
       "      <td>GRAND CONCOURSE</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>365</td>\n",
       "      <td>121</td>\n",
       "      <td>5957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.724393</td>\n",
       "      <td>-73.849776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key  incident_zip incident_address      street_name    city  \\\n",
       "count       18970           0.0            18969            18969     127   \n",
       "unique      18970           NaN             8306             2205       2   \n",
       "top      24973466           NaN  34 ARDEN STREET  GRAND CONCOURSE  QUEENS   \n",
       "freq            1           NaN              232              365     121   \n",
       "mean          NaN           NaN              NaN              NaN     NaN   \n",
       "std           NaN           NaN              NaN              NaN     NaN   \n",
       "min           NaN           NaN              NaN              NaN     NaN   \n",
       "25%           NaN           NaN              NaN              NaN     NaN   \n",
       "50%           NaN           NaN              NaN              NaN     NaN   \n",
       "75%           NaN           NaN              NaN              NaN     NaN   \n",
       "max           NaN           NaN              NaN              NaN     NaN   \n",
       "\n",
       "       borough   latitude  longitude  \n",
       "count    18970   4.000000   4.000000  \n",
       "unique       6        NaN        NaN  \n",
       "top      BRONX        NaN        NaN  \n",
       "freq      5957        NaN        NaN  \n",
       "mean       NaN  40.724393 -73.849776  \n",
       "std        NaN   0.000000   0.000000  \n",
       "min        NaN  40.724393 -73.849776  \n",
       "25%        NaN  40.724393 -73.849776  \n",
       "50%        NaN  40.724393 -73.849776  \n",
       "75%        NaN  40.724393 -73.849776  \n",
       "max        NaN  40.724393 -73.849776  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There were some null zip codes.  Examine them more closely.\n",
    "df[df['incident_zip'].isnull()==True].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There is nothing \"worth the trouble\" in the data upon which to try to fill in the missing zip codes.  If these 18K rows were deemed super important, a library for looking up a zip code based on an address would be necessary.  Because these rows still have Borough, don't drop the row.  Just leave them as NaN values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>borough</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251660</th>\n",
       "      <td>21833329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key  incident_zip incident_address street_name city borough  \\\n",
       "251660   21833329           NaN              NaN         NaN  NaN   BRONX   \n",
       "\n",
       "        latitude  longitude  \n",
       "251660       NaN        NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the one row with the missing street.\n",
    "df[df[\"street_name\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There is nothing in the data upon which to base a guess to the street.  In order to keep anticipated later standardization of the street_name simpler, get rid of the null row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop it.\n",
    "df.drop(df[df[\"street_name\"].isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardize values from different sources into the same format, units, or convention\n",
    "I'm going to go a little overboard here, well past the point of diminishing returns.  Just for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  While looking for null values, I noticed there were rows with the city missing.  How could the city ever be missing, when the borough is filled in?  Let's explore the data to answer this question.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize all strings to uppercase so different casing won't appear as separate values.\n",
    "df['incident_address'] = df['incident_address'].str.upper()\n",
    "df['street_name'] = df['street_name'].str.upper()\n",
    "df['city'] = df['city'].str.upper()\n",
    "df['borough'] = df['borough'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            569959\n",
       "BROOKLYN         543166\n",
       "MANHATTAN        398552\n",
       "UNSPECIFIED      282917\n",
       "QUEENS           228447\n",
       "STATEN ISLAND     17419\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The expected five boroughs, but then also:  UNSPECIFIED.  What does that mean?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BROOKLYN               93388\n",
       "BRONX                  88585\n",
       "NEW YORK               59095\n",
       "JAMAICA                 5020\n",
       "STATEN ISLAND           3462\n",
       "ASTORIA                 3381\n",
       "FLUSHING                3154\n",
       "RIDGEWOOD               2273\n",
       "FAR ROCKAWAY            2040\n",
       "WOODSIDE                1773\n",
       "ELMHURST                1696\n",
       "JACKSON HEIGHTS         1479\n",
       "CORONA                  1398\n",
       "FOREST HILLS            1340\n",
       "REGO PARK               1134\n",
       "SOUTH RICHMOND HILL     1005\n",
       "QUEENS VILLAGE           928\n",
       "SUNNYSIDE                877\n",
       "OZONE PARK               835\n",
       "RICHMOND HILL            778\n",
       "HOLLIS                   776\n",
       "WOODHAVEN                770\n",
       "EAST ELMHURST            752\n",
       "SPRINGFIELD GARDENS      675\n",
       "SAINT ALBANS             660\n",
       "SOUTH OZONE PARK         606\n",
       "KEW GARDENS              599\n",
       "ARVERNE                  589\n",
       "LONG ISLAND CITY         454\n",
       "ROSEDALE                 416\n",
       "OAKLAND GARDENS          397\n",
       "MASPETH                  363\n",
       "ROCKAWAY PARK            361\n",
       "BAYSIDE                  236\n",
       "COLLEGE POINT            225\n",
       "FRESH MEADOWS            225\n",
       "MIDDLE VILLAGE           221\n",
       "LITTLE NECK              159\n",
       "WHITESTONE               139\n",
       "HOWARD BEACH             127\n",
       "CAMBRIA HEIGHTS          127\n",
       "GLEN OAKS                 56\n",
       "BELLEROSE                 45\n",
       "FLORAL PARK               18\n",
       "BREEZY POINT               6\n",
       "QUEENS                     3\n",
       "NEW HYDE PARK              2\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"borough\"]==\"UNSPECIFIED\"][\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  When the borough is UNSPECIFIED it appears to mean that often either the borough <i>or even a \"neighborhood\" (a division below borough)</i> has been entered in the CITY column.  The city is actually \"correct\" with NEW YORK only 59K times.  The city column is a de-facto \"neighborhood\" column for the most part.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Because borough is something further analysis will key from, standardize the data where possible.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Correct rows where borough was entered in the city column with \"UNSPECIFIED\" in the borough column.\n",
    "five_boroughs = [\"BROOKLYN\",\"BRONX\",\"MANHATTAN\",\"QUEENS\",\"STATEN ISLAND\"]\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(five_boroughs)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=df.loc[which_rows_to_adjust,'city']\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">Almost 200K previously \"UNSPECIFIED\" rows will now show up under the correct borough during later analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MANHATTAN      393941\n",
       "UNSPECIFIED     59095\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if all the boroughs encompassed when the CITY is showing up as \"New York\"\n",
    "df[df['city']=='NEW YORK']['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEW YORK    393941\n",
       "BRONX            9\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See if all the MANHATTAN borough entries filled in the CITY as \"New York\" if if they sometimes have \"neighborhood\".\n",
    "df[df['borough']=='MANHATTAN']['city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Some data entered very oddly with BRONX as the city and MANHATTAN as the borough.  Ambiguous and only 9 rows out of millions, so drop the data so it won't confuse further analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040460, 8)\n",
      "(2040451, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #before\n",
    "#Drop a few rows of ambiguous data.\n",
    "df.drop(df[(df[\"borough\"]=='MANHATTAN')&(df[\"city\"]=='BRONX')].index, axis=0, inplace=True)\n",
    "print(df.shape) #after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There are almost 400K rows with city as NEW YORK and the borough is MANHATTAN.  The other 59K rows with city NEW YORK has UNSPECIFIED as the borough.  Assume the borough is also MANHATTAN for those.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in UNSPECIFIED borough when city was entered as NEW YORK.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"MANHATTAN\"\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Although the city for most of the \"NEW YORK\" ones are the only ones that technically got the \"city\" column valued correctly,\n",
    "#since every other row uses city as \"neighborhood\":  Standardize these.\n",
    "which_rows_to_adjust = df[(df[\"city\"]=='NEW YORK')].index\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            658544\n",
       "BROOKLYN         636554\n",
       "MANHATTAN        457638\n",
       "QUEENS           228450\n",
       "UNSPECIFIED       38384\n",
       "STATEN ISLAND     20881\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check how many unspecified boroughs.\n",
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  There are still 38K rows with unspecified boroughs, but the neighborhoods are in the city column, so use them to map to boroughs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ARVERNE', 'ASTORIA', 'BAYSIDE', 'BELLEROSE', 'BREEZY POINT',\n",
       "       'CAMBRIA HEIGHTS', 'COLLEGE POINT', 'CORONA', 'EAST ELMHURST',\n",
       "       'ELMHURST', 'FAR ROCKAWAY', 'FLORAL PARK', 'FLUSHING',\n",
       "       'FOREST HILLS', 'FRESH MEADOWS', 'GLEN OAKS', 'HOLLIS',\n",
       "       'HOWARD BEACH', 'JACKSON HEIGHTS', 'JAMAICA', 'KEW GARDENS',\n",
       "       'LITTLE NECK', 'LONG ISLAND CITY', 'MASPETH', 'MIDDLE VILLAGE',\n",
       "       'NEW HYDE PARK', 'OAKLAND GARDENS', 'OZONE PARK', 'QUEENS VILLAGE',\n",
       "       'REGO PARK', 'RICHMOND HILL', 'RIDGEWOOD', 'ROCKAWAY PARK',\n",
       "       'ROSEDALE', 'SAINT ALBANS', 'SOUTH OZONE PARK',\n",
       "       'SOUTH RICHMOND HILL', 'SPRINGFIELD GARDENS', 'SUNNYSIDE',\n",
       "       'WHITESTONE', 'WOODHAVEN', 'WOODSIDE'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the neighborhoods of the still unspecified boroughs.\n",
    "neighborhoods = df[(df['borough']=='UNSPECIFIED')&(df['city'].isnull()==False)]['city'].unique()\n",
    "neighborhoods.sort()\n",
    "neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  Checking https://en.wikipedia.org/wiki/List_of_Queens_neighborhoods show all but NEW HYDE PARK are in QUEENS.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  NEW HYDE PARK isn't in any borough but is right on the border with QUEENS, and had only 2 complaints, so just consider it within QUEEENS.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRONX            658544\n",
       "BROOKLYN         636554\n",
       "MANHATTAN        457638\n",
       "QUEENS           266565\n",
       "STATEN ISLAND     20881\n",
       "UNSPECIFIED         269\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fix rows with unspecified borough but with a neighborhood (in the city column) that indicates it is in QUEEENS.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isin(neighborhoods)].index\n",
    "df.loc[which_rows_to_adjust,'borough']=\"QUEENS\"\n",
    "df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  The above will ultimately become the raw numbers to partially answer part of the the question.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incident_zip  latitude  longitude\n",
       "count           0.0       0.0        0.0\n",
       "mean            NaN       NaN        NaN\n",
       "std             NaN       NaN        NaN\n",
       "min             NaN       NaN        NaN\n",
       "25%             NaN       NaN        NaN\n",
       "50%             NaN       NaN        NaN\n",
       "75%             NaN       NaN        NaN\n",
       "max             NaN       NaN        NaN"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine rows for those final 269 unspecified boroughs\n",
    "df[df['borough']=='UNSPECIFIED'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Decision</b>:  Nothing \"worth the trouble\" to base further adjustments on for only 269 rows.  Set the borough to null on these rows so that they will not skew any subsequent analysis that examines borough.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with unspecified borough and no other practical information from which to derive it.\n",
    "which_rows_to_adjust = df[(df[\"borough\"]=='UNSPECIFIED')&df[\"city\"].isnull()].index\n",
    "df.loc[which_rows_to_adjust,'borough']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with city (neighborhood) equal to borough\n",
    "which_rows_to_adjust = df[(df[\"borough\"]==df[\"city\"])].index\n",
    "df.loc[which_rows_to_adjust,'city']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix rows with city that started off null or was adjusted subsequently to be null\n",
    "which_rows_to_adjust = df[df[\"city\"].isnull()].index\n",
    "df.loc[which_rows_to_adjust,'city']=\"Unspecified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">At this point borough is reasonably populated with all the UNSPECIFIED and weird cases standardized.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18969, 8)\n",
      "(2021482, 8)\n",
      "(2021482, 8)\n",
      "(0, 8)\n",
      "(0, 8)\n",
      "(2021482, 8)\n"
     ]
    }
   ],
   "source": [
    "#Learn the nature of the zip code data.\n",
    "print(df[(df['incident_zip'].isnull()==True)].shape)\n",
    "print(df[(df['incident_zip'].isnull()==False)].shape)\n",
    "print(df[(df['incident_zip'].isnull()==False)&(df['incident_zip'] % 1.0 == 0.0)].shape)\n",
    "print(df[(df['incident_zip']<10000.0)].shape)\n",
    "print(df[(df['incident_zip']>99999.0)].shape)\n",
    "print(df[(df['incident_zip']>9999.0)&(df['incident_zip']<100000.0)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  The zip codes are all float64.  All of them have zero after the decimal point.  They are all five digits before the decimal point.  Almost 19K of the 2 Million+ rows are null.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">The question calls for using street too.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRAND CONCOURSE             35960\n",
       "BROADWAY                    23497\n",
       "OCEAN AVENUE                17882\n",
       "ARDEN STREET                15841\n",
       "MORRIS AVENUE               15792\n",
       "ST NICHOLAS AVENUE          14945\n",
       "AMSTERDAM AVENUE            11844\n",
       "ELMHURST AVENUE             10946\n",
       "BOYNTON AVENUE              10809\n",
       "DR M L KING JR BOULEVARD    10037\n",
       "OCEAN PARKWAY                9965\n",
       "WALTON AVENUE                9579\n",
       "BAILEY AVENUE                9561\n",
       "RIVERSIDE DRIVE              9189\n",
       "LINDEN BOULEVARD             9173\n",
       "SEDGWICK AVENUE              9111\n",
       "DECATUR AVENUE               9095\n",
       "NOSTRAND AVENUE              8826\n",
       "CRESTON AVENUE               8683\n",
       "SHERMAN AVENUE               7885\n",
       "BEDFORD AVENUE               7530\n",
       "SHERIDAN AVENUE              7502\n",
       "EASTERN PARKWAY              7424\n",
       "3 AVENUE                     7323\n",
       "WALLACE AVENUE               7287\n",
       "2 AVENUE                     7172\n",
       "DAVIDSON AVENUE              6840\n",
       "FT WASHINGTON AVENUE         6698\n",
       "NEW YORK AVENUE              6663\n",
       "VALENTINE AVENUE             6565\n",
       "                            ...  \n",
       "EDGERTON BOULEVARD              1\n",
       "OUTERBRIDGE AVENUE              1\n",
       "VANSICLEN AVENUE                1\n",
       "BRIGHTON    2 LANE              1\n",
       "ELWOOD AVENUE                   1\n",
       "RAVENHURST AVENUE               1\n",
       "SWAIM AVENUE                    1\n",
       "LYNHURST AVENUE                 1\n",
       "IRWIN STREET                    1\n",
       "5 AVE                           1\n",
       "DUMFRIES PLACE                  1\n",
       "BRADEY AVENUE                   1\n",
       "CLARKE PLACE                    1\n",
       "GUNNISON COURT                  1\n",
       "LORING AVE                      1\n",
       "HARPER STREET                   1\n",
       "FITCHETT STREET                 1\n",
       "BRIGHTON    1 LANE              1\n",
       "BACHE STREET                    1\n",
       "DOOLEY STREET                   1\n",
       "AVENUE ST JOHNS                 1\n",
       "PAERDEGAT    4 STREET           1\n",
       "SOUTH MANN AVENUE               1\n",
       "HULL                            1\n",
       "WEST 263 STREET                 1\n",
       "KINGHORN STREET                 1\n",
       "E191 ST                         1\n",
       "E 78 ST                         1\n",
       "BURNETT PLACE                   1\n",
       "PROVOST AVENUE                  1\n",
       "Name: street_name, Length: 5979, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insight</b>:  Before any attempt at standardization, there are 5979 distinct street_name values in the data.  There does not appear to be much standardization in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Goal</b>:  Standardize the street names so different representations of the same street are all counted into the same totals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Insights</b></p>\n",
    "<p>This section will be added to over and over again with any insights gleaned during the running of cells in the subsequent \"Work area\" section.  This section is placed ahead of that one because sometimes the insights will usually be captured in the form of coded lists or even function definitions which will be re-run every time they change.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some street values have multiple spaces in a row.\n",
    "import re\n",
    "def standardize_spaces(raw):\n",
    "    result = raw.strip() #Remove leading and trailing spaces.\n",
    "    result = re.sub(' +', ' ', result) #Squeeze multiple adjacent spaces into just one space.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some streets have problematic characters.  For example:  ST. ANN'S AVENUE also exists without period or apostophe.\n",
    "problem_characters = ['.', '\\'']\n",
    "def replace_problem_characters(raw):\n",
    "    result = raw\n",
    "    for (character) in problem_characters:\n",
    "        result = result.replace(character,'')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streets are not always called a street.\n",
    "street_suffixes = [\n",
    "    \"STREET\",\"AVENUE\",\"BOULEVARD\",\"PLACE\",\"ROAD\",\"PARKWAY\",\"CONCOURSE\",\"DRIVE\",\n",
    "    \"TERRACE\",\"HIGHWAY\",\"PARK\",\"EXPRESSWAY\",\"SQUARE\",\"PLAZA\",\"OVAL\",\"CRESCENT\",\n",
    "    \"LANE\",\"COURT\",\"EXTENSION\",\"TURNPIKE\", \"LOOP\", \"ESTATE\", \"WAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streets often have a directional element\n",
    "street_directionals = [\"SOUTH\",\"NORTH\",\"EAST\",\"WEST\",\"SOUTHWEST\",\"NORTHWEST\",\"SOUTHEAST\",\"NORTHEAST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some words that are entered in a non-standard way or with typos need to be standardized.\n",
    "word_replacements = [\n",
    "    (\"AVE\",\"AVENUE\"),\n",
    "    (\"ST\",\"STREET\"),\n",
    "    (\"RD\",\"ROAD\"),\n",
    "    (\"FT\",\"FORT\"),\n",
    "    (\"BX\",\"BRONX\"),\n",
    "    (\"MT\",\"MOUNT\"),\n",
    "    (\"NICHLAS\",\"NICHOLAS\"),\n",
    "    (\"NICHALOS\",\"NICHOLAS\"),\n",
    "    (\"EXPRE\",\"EXPRESSWAY\"),\n",
    "    (\"HARACE\",\"HORACE\"),\n",
    "    (\"NO\",\"NORTH\"), \n",
    "    (\"AV\",\"AVENUE\"), \n",
    "    (\"CRK\",\"CREEK\"),\n",
    "    (\"FR\",\"FATHER\"),\n",
    "    (\"JR\",\"JUNIOR\"),\n",
    "    (\"GR\",\"GRAND\"),\n",
    "    (\"CT\",\"COURT\"),\n",
    "    (\"SR\",\"\"), # Service Road.  These are always near a similarly named street.\n",
    "    (\"QN\",\"QUEENS\"),\n",
    "    (\"ND\",\"\"), # A space between a number and ND such as EAST 52 ND STREET\n",
    "    (\"PO\",\"POND\"),\n",
    "    (\"BO\",\"BOND\"),\n",
    "    (\"GRA\",\"GRAND\"),\n",
    "    (\"REV\",\"REVEREND\"),\n",
    "    (\"CO-OP\",\"COOP\"),\n",
    "    (\"GRANDCONCOURSE\", \"GRAND CONCOURSE\"),\n",
    "    (\"CENTRL\", \"CENTRAL\"),\n",
    "    (\"BLVD\",\"BOULEVARD\"),\n",
    "    (\"FREDRICK\", \"FREDERICK\"),\n",
    "    (\"DOUGLAS\", \"DOUGLASS\"),\n",
    "    (\"MALCOM\", \"MALCOMN\"),\n",
    "    (\"NORTHEN\", \"NORTHERN\"),\n",
    "    (\"AVNEUE\",\"AVENUE\")\n",
    "]\n",
    "\n",
    "def replace_words(raw):\n",
    "    split_raw = raw.split()\n",
    "    for (old, new) in word_replacements:\n",
    "        found_at_index = next((i for i, x in enumerate(split_raw) if x==old), None)\n",
    "        if found_at_index!=None:\n",
    "            split_raw[found_at_index] = new\n",
    "            return standardize_spaces(\" \".join(split_raw))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abbreviations that are sometimes not abbreviations.  Example:  AVENUE N.\n",
    "abbreviation_replacements = [\n",
    "    (\"N\",\"NORTH\"),\n",
    "    (\"S\",\"SOUTH\"),\n",
    "    (\"E\",\"EAST\"),\n",
    "    (\"W\",\"WEST\"),\n",
    "    (\"SW\",\"SOUTHWEST\"),\n",
    "    (\"NW\",\"NORTHWEST\"),\n",
    "    (\"SE\",\"SOUTHEAST\"),\n",
    "    (\"NE\",\"NORTHEAST\")\n",
    "]\n",
    "\n",
    "def replace_tricky_abbreviations(raw):\n",
    "    split_raw = raw.split()\n",
    "    if len(split_raw)!=2:  # AVENUE N, E STREET, etc.\n",
    "        for (old, new) in abbreviation_replacements:\n",
    "            found_at_index = next((i for i, x in enumerate(split_raw) if x==old), None)\n",
    "            if found_at_index!=None:\n",
    "                split_raw[found_at_index] = new\n",
    "                return \" \".join(split_raw)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some words are actually prefixes of the following word.\n",
    "word_prefixes = [\"DE\",\"MC\",\"LA\",\"VAN\",\"MAC\",\"CO\"]\n",
    "\n",
    "def concatenate_prefixes(raw):\n",
    "    split_raw = raw.split()\n",
    "    last_word = len(split_raw) - 1\n",
    "    for (prefix) in word_prefixes:\n",
    "        found_at_index = next((i for i, x in enumerate(split_raw) if x==prefix), None)\n",
    "        if found_at_index!=None:\n",
    "            if len(split_raw)>1:\n",
    "                if found_at_index != last_word:\n",
    "                    split_raw[found_at_index] = ''\n",
    "                    split_raw[found_at_index+1] = prefix + split_raw[found_at_index+1]\n",
    "                    return standardize_spaces(\" \".join(split_raw))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some phrases need custom replacement because they involve words that individually would be mis-interpretted.\n",
    "phrase_replacements = [\n",
    "    (\"DR M L KING JR\",\"MARTIN LUTHER KING\"),\n",
    "    (\"DR MARTIN L KING\",\"MARTIN LUTHER KING\"),\n",
    "    (\"MARTIN LUTHER KING\",\"MARTIN LUTHER KING\"),\n",
    "    (\"MARTIN L KING JR\",\"MARTIN LUTHER KING\"),\n",
    "    (\"MARTIN L KING\",\"MARTIN LUTHER KING\"),\n",
    "    (\"ST NICHOLAS\",\"SAINT NICHOLAS\"),\n",
    "    (\"ST JOHN\",\"SAINT JOHN\"),\n",
    "    (\"ST MARK\",\"SAINT MARK\"),\n",
    "    (\"ST ANN\",\"SAINT ANN\"),\n",
    "    (\"ST LAWRENCE\",\"SAINT LAWRENCE\"),\n",
    "    (\"ST PAUL\",\"SAINT PAUL\"),\n",
    "    (\"ST PETER\",\"SAINT PETER\"),\n",
    "    (\"ST RAYMOND\",\"SAINT RAYMOND\"),\n",
    "    (\"ST THERESA\",\"SAINT THERESA\"),\n",
    "    (\"ST FELIX\",\"SAINT FELIX\"),\n",
    "    (\"ST MARY\",\"SAINT MARY\"),\n",
    "    (\"ST OUEN\",\"SAINT OUEN\"),\n",
    "    (\"ST JAMES\",\"SAINT JAMES\"),\n",
    "    (\"ST GEORGE\",\"SAINT GEORGE\"),\n",
    "    (\"ST EDWARD\",\"SAINT EDWARD\"),\n",
    "    (\"ST CHARLES\",\"SAINT CHARLES\"),\n",
    "    (\"ST FRANCIS\",\"SAINT FRANCIS\"),\n",
    "    (\"ST ANDREW\",\"SAINT ANDREW\"),\n",
    "    (\"ST JUDE\",\"SAINT JUDE\"),\n",
    "    (\"ST LUKE\",\"SAINT LUKE\"),\n",
    "    (\"ST JOSEPH\",\"SAINT JOSEPH\"),\n",
    "    (\"N D PERLMAN\",\"NATHAN PERLMAN\"),\n",
    "    (\"O BRIEN\",\"OBRIEN\"),\n",
    "    (\"F D R\",\"FDR\"),\n",
    "    (\"EXPRESSWAY N SR\",\"EXPRESSWAY SR N\"),\n",
    "    (\"HOR HARDING\",\"HORACE HARDING\"),\n",
    "    (\"SERVICE ROAD\",\"\"), # These are always near a similarly named street\n",
    "    (\"DUMMY\",\"\"),\n",
    "    (\"ADAM C POWELL\",\"ADAM CLAYTON POWELL\"),\n",
    "    (\"POWELL COVE\",\"POWELLS COVE\")\n",
    "]\n",
    "\n",
    "def replace_phrases(raw):\n",
    "    result = raw\n",
    "    for (old,new) in phrase_replacements:\n",
    "        result = standardize_spaces(result.replace(old,new))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ST, 2ND, 3RD, 4TH, ... nTH\n",
    "number_suffixes = [\"ST\",\"ND\",\"RD\",\"TH\"]\n",
    "digits=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"]\n",
    "def remove_number_suffixes(raw):\n",
    "    split_raw = raw.split()\n",
    "    for suffix in number_suffixes:\n",
    "        found_at_index = next((i for i, x in enumerate(split_raw) if x[0] in digits and x.endswith(suffix)), None) \n",
    "        if found_at_index!=None:            \n",
    "            split_raw[found_at_index] = split_raw[found_at_index][:-2]\n",
    "            return standardize_spaces(\" \".join(split_raw))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different words of each address can be essentially the same but in different orders.  Standardize the order.\n",
    "#\n",
    "# A:  All Numbers, in numerical order.\n",
    "# B:  All Street Suffixes, in alphabetical order.\n",
    "# C:  All Directionals, in alphabetical order.\n",
    "# D:  All other words, in alphabetical within descending word length order.\n",
    "#\n",
    "# The above in this sequence:  B, A, D, C\n",
    "\n",
    "def alphabetical_within_word_length(raw):\n",
    "    return \"{:03d}\".format(999-len(raw)) + raw\n",
    "\n",
    "def standardize_word_order(raw):\n",
    "    numbers = []\n",
    "    suffixes = []\n",
    "    directionals = []\n",
    "    other = []\n",
    "    words = raw.split()\n",
    "    for word in words:\n",
    "        if word.isdigit()==True:\n",
    "            numbers.append(word)\n",
    "        elif word in street_suffixes:\n",
    "            suffixes.append(word)\n",
    "        elif word in street_directionals:\n",
    "            directionals.append(word)\n",
    "        else:\n",
    "            other.append(word)\n",
    "        numbers.sort()\n",
    "        suffixes.sort()\n",
    "        directionals.sort()\n",
    "        other.sort(key=alphabetical_within_word_length)\n",
    "    result = []\n",
    "    result.extend(suffixes)\n",
    "    result.extend(numbers)\n",
    "    result.extend(other)\n",
    "    result.extend(directionals)\n",
    "    return standardize_spaces(\" \".join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Standardize Function</b></p>\n",
    "<p>This function will be built up gradually as insights are gained.  Ultimately resulting in a single function that will standardize a street name.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_street(street):\n",
    "    r = street\n",
    "    r = standardize_spaces(r)\n",
    "    r = replace_problem_characters(r)\n",
    "    r = replace_phrases(r)\n",
    "    r = replace_words(r)\n",
    "    r = replace_tricky_abbreviations(r)\n",
    "    r = concatenate_prefixes(r)\n",
    "    r = remove_number_suffixes(r)\n",
    "    r = standardize_word_order(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\"><b>Work area</b></p>\n",
    "<p>The following sections will be run over and over again, not necessarily in order.  Each time with modifications to filter out words already considered, or to drill into a specific case under consideration for further insights.  Each time, the insights gained will be applied within the \"Insights\" section above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions to use with the Pandas DataFrame \"apply\" function for filtering out very specific sets of data.\n",
    "\n",
    "def is_word_present(x, word):\n",
    "    split_x = x.split()\n",
    "    if word in split_x:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_either_word_present(x, w1, w2):\n",
    "    if is_word_present(x,w1):\n",
    "        return True\n",
    "    if is_word_present(x,w2):\n",
    "        return True    \n",
    "    return False    \n",
    "    \n",
    "def is_not_last_word(x, word):\n",
    "    split_x = x.split()\n",
    "    last_word = len(split_x) - 1\n",
    "    if word!=last_word:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_word_present_but_not_last(x, word):\n",
    "    if is_word_present(x,word):\n",
    "        if is_not_last_word(x,word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_small_alpha_word_present(x, size):\n",
    "    split_x = x.split()\n",
    "    for a in split_x:\n",
    "        if len(a)==size:\n",
    "            if a.isalpha():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def any_word_start_with(x, front):\n",
    "    split_x = x.split()\n",
    "    for a in split_x:\n",
    "        if a.startswith(front):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize what we can\n",
    "df['standardized_street_name'] = df['street_name'].apply(standardize_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the partially standardized results to gain more insights.\n",
    "#The following cell needs to change often.  Only the most common types of lines are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONCOURSE GRAND                 36247\n",
       "BROADWAY                        23497\n",
       "AVENUE OCEAN                    17882\n",
       "STREET ARDEN                    15841\n",
       "AVENUE MORRIS                   15793\n",
       "AVENUE NICHOLAS SAINT           14945\n",
       "AVENUE AMSTERDAM                11845\n",
       "AVENUE ELMHURST                 10947\n",
       "AVENUE BOYNTON                  10809\n",
       "BOULEVARD LUTHER MARTIN KING    10244\n",
       "PARKWAY OCEAN                    9965\n",
       "AVENUE WALTON                    9579\n",
       "AVENUE BAILEY                    9561\n",
       "DRIVE RIVERSIDE                  9189\n",
       "BOULEVARD LINDEN                 9173\n",
       "AVENUE SEDGWICK                  9111\n",
       "AVENUE DECATUR                   9095\n",
       "AVENUE NOSTRAND                  8826\n",
       "AVENUE CRESTON                   8684\n",
       "AVENUE SHERMAN                   7885\n",
       "AVENUE BEDFORD                   7531\n",
       "AVENUE SHERIDAN                  7504\n",
       "PARKWAY EASTERN                  7424\n",
       "AVENUE 3                         7323\n",
       "AVENUE WALLACE                   7287\n",
       "AVENUE DEKALB                    7180\n",
       "AVENUE 2                         7172\n",
       "AVENUE DAVIDSON                  6840\n",
       "AVENUE WASHINGTON FORT           6703\n",
       "AVENUE YORK NEW                  6663\n",
       "                                ...  \n",
       "PLACE 42                            1\n",
       "AVENUE KENWOOD                      1\n",
       "COURT 1                             1\n",
       "AVENUE BAYRIDGE                     1\n",
       "BOULEVARD AMSTEL                    1\n",
       "STREET SANDGAP                      1\n",
       "PLACE PONTIAC                       1\n",
       "AVENUE OUTERBRIDGE                  1\n",
       "PLACE 208                           1\n",
       "AVENUE GURLEY                       1\n",
       "STREET COOKE                        1\n",
       "PLACE LISBON                        1\n",
       "PLACE GRAY                          1\n",
       "LANE SAMANTHA                       1\n",
       "STREET ABBOT                        1\n",
       "ROAD CAMBRIDGE                      1\n",
       "AVENUE RHETT                        1\n",
       "STREET 135 BEACH                    1\n",
       "BOULEVARD POWELL COVE               1\n",
       "TERRACE 73                          1\n",
       "TERRACE FIELDSTONE                  1\n",
       "CRESCENT DIETERLE                   1\n",
       "STREET GREENPORT                    1\n",
       "AVENUE CORONA NORTH                 1\n",
       "COURT 235                           1\n",
       "LANE MIMOSA                         1\n",
       "WAY CORAL REEF                      1\n",
       "ROAD FOREST                         1\n",
       "AVENUE TASP                         1\n",
       "AVENUE EVA                          1\n",
       "Name: standardized_street_name, Length: 5142, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5142 with order standardization.  Only gained 3 from 5145, but easier to examine them to find other patterns.\n",
    "df['standardized_street_name'].value_counts()\n",
    "#df[df['standardized_street_name'].apply(is_small_alpha_word_present, args=(4,))]['standardized_street_name'].value_counts()\n",
    "#df[df['standardized_street_name'].apply(is_word_present, args=(\"COOP\",))]['standardized_street_name'].value_counts()\n",
    "#df[df['standardized_street_name'].apply(is_either_word_present, args=(\"SE\",\"SOUTHEAST\",))]['standardized_street_name'].value_counts()\n",
    "#df[df['standardized_street_name'].apply(xxx)]['standardized_street_name'].value_counts()\n",
    "\n",
    "#df[df['standardized_street_name'].str.contains('ADAM')]['standardized_street_name'].value_counts()\n",
    "\n",
    "#df[df['street_name'].str.contains('SOUTHWEST')]['street_name'].value_counts()\n",
    "\n",
    "#uni = df[df['standardized_street_name'].str.startswith('AVENUE')]['standardized_street_name'].unique()\n",
    "#uni.sort()uni.sort()\n",
    "#for i in uni.astype(str):\n",
    "#    print (i[7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AVENUE          869616\n",
       "STREET          786742\n",
       "EAST            248311\n",
       "WEST            179604\n",
       "BOULEVARD        76976\n",
       "PLACE            76390\n",
       "ROAD             59025\n",
       "PARKWAY          48542\n",
       "GRAND            44118\n",
       "CONCOURSE        36884\n",
       "SAINT            35200\n",
       "OCEAN            28277\n",
       "BROADWAY         24642\n",
       "PARK             24258\n",
       "NICHOLAS         17809\n",
       "MORRIS           17225\n",
       "SOUTH            16056\n",
       "ARDEN            15847\n",
       "DRIVE            15639\n",
       "WASHINGTON       13737\n",
       "NORTH            13426\n",
       "BEACH            13079\n",
       "AMSTERDAM        11845\n",
       "3                11238\n",
       "LINDEN           10995\n",
       "BEDFORD          10988\n",
       "ELMHURST         10947\n",
       "TERRACE          10942\n",
       "BOYNTON          10815\n",
       "DECATUR          10775\n",
       "                 ...  \n",
       "GLORIA               1\n",
       "ALVERSON             1\n",
       "COURTNEY             1\n",
       "HASPEL               1\n",
       "MARGARET             1\n",
       "MARK                 1\n",
       "NAVIGATOR            1\n",
       "HUBERT               1\n",
       "LAGUNA               1\n",
       "MCCULLY              1\n",
       "HAMLIN               1\n",
       "LINDA                1\n",
       "ASTER                1\n",
       "WINDING              1\n",
       "ALTON                1\n",
       "ARIEL                1\n",
       "LUGUER               1\n",
       "RIVIERA              1\n",
       "ZION                 1\n",
       "PENNSYLVAN           1\n",
       "BARUCH               1\n",
       "266                  1\n",
       "BARRY                1\n",
       "ISABELLA             1\n",
       "FLAGG                1\n",
       "CHORNEYNESTE         1\n",
       "JULIE                1\n",
       "PERONA               1\n",
       "MICHAEL              1\n",
       "WHEATLEY             1\n",
       "Length: 3084, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all of the individual words represented within the street_name column in a countable form.\n",
    "words = list()\n",
    "df['standardized_street_name'].str.split().apply(words.extend)\n",
    "word_series = pd.Series(words)\n",
    "counts = word_series.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1295,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop words that don't appear often enough to fuss with\n",
    "counts.drop(counts[counts < 100].index, inplace=True) \n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050,)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop words that are ONLY numbers\n",
    "counts.drop(counts[counts.index.str.isdigit()].index, inplace=True) \n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAGLE             546\n",
       "EAST           248311\n",
       "EASTBURN         1012\n",
       "EASTCHESTER       278\n",
       "EASTERN          8104\n",
       "EBBITTS           143\n",
       "ECHO              367\n",
       "ECKFORD           232\n",
       "EDEN              203\n",
       "EDENWALD          111\n",
       "EDGECOMBE        3672\n",
       "EDISON            375\n",
       "EDSON             238\n",
       "EDWARD            682\n",
       "EDWARDS           164\n",
       "ELBERTSON         502\n",
       "ELDER            1919\n",
       "ELDERT           1157\n",
       "ELDERTS           106\n",
       "ELDRIDGE          912\n",
       "ELIZABETH         624\n",
       "ELK               345\n",
       "ELLERY            121\n",
       "ELLIOT           1142\n",
       "ELLIOTT           124\n",
       "ELLIS             548\n",
       "ELLWOOD          1895\n",
       "ELM               239\n",
       "ELMHURST        10947\n",
       "ELMWOOD           342\n",
       "ELSMERE           429\n",
       "ELTON            1307\n",
       "ELY               209\n",
       "EMMONS            743\n",
       "EMPIRE           1984\n",
       "END              3675\n",
       "ERASMUS           893\n",
       "ERICSON           516\n",
       "ESPLANADE         461\n",
       "ESSEX            1147\n",
       "ETNA              524\n",
       "EUCLID            590\n",
       "EVELYN            168\n",
       "EVERGREEN        2470\n",
       "EXPRESSWAY       2756\n",
       "EXTENSION         684\n",
       "EYCK              122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine groups of words in sorted order to detect ones that are probably different forms of the same word.\n",
    "counts[counts.index.str.startswith(\"E\")].sort_index()\n",
    "#counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Went from 5979 to 5142 unique streets by standardizing to reduce different representations of the same street."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">What standardizations can we do based on these insights?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['street_name'].str.contains('CONCOURSE')]['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_width_max = df['borough'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather totals for graphic\n",
    "totals_for_graph = df['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "totals_for_graph.plot(kind='barh', figsize=(13, 4), color='steelblue')\n",
    "plt.xlim = (0, graph_width_max)\n",
    "plt.xlabel('Number of complaints')\n",
    "plt.title('HEATING / HOT WATER complaints by borough')\n",
    "for index, value in enumerate(totals_for_graph): \n",
    "    label = format(int(value), ',') # format int with commas\n",
    "    # place text at the end of bar (subtracting 47000 from x, and 0.1 from y to make it fit within the bar)\n",
    "    plt.annotate(label, xy=(value - 47000, index - 0.10), color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Concluding Remarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Department of Housing Preservation and Development of New York City should focus on the following particular set of boroughs, ZIP codes, and streets (where the complaints are severe) for the \"HEAT/HOT WATER\" + \"HEATING\" complaint types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red;\">xxx</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
